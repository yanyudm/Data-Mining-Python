{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1ZkbNmmdLKT"
   },
   "source": [
    "# **Advanced Tree Models – Boosting Trees**\n",
    "\n",
    "Maintainer: Zhaohu(Jonathan) Fan. Contact him at (psujohnny@gmail.com)\n",
    "\n",
    "\n",
    "Note: This lab note is still WIP, let us know if you encounter bugs or issues.\n",
    "\n",
    "1. [Boosting](#1-boosting)  \n",
    "   1.1 [Boosting for Regression Trees](#11-boosting-for-regression-trees)  \n",
    "   1.2 [Boosting for Classification Trees](#12-boosting-for-classification-trees)  \n",
    "\n",
    "\n",
    "#### *Colab Notebook [Open in Colab](https://colab.research.google.com/drive/1Ud1aLBXB0ZHnQlvDuUmueYCjG4D4UHBU?usp=sharing)*\n",
    "\n",
    "#### *Useful information about [Advanced Tree Models – Boosting Trees in R](https://yanyudm.github.io/Data-Mining-R/lecture/7.C_Boosting.html)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wuct80hAsN9h"
   },
   "source": [
    "## Lab Overview\n",
    "\n",
    "In this lab, we will cover state-of-the-art techniques within the tree-modeling framework. We will use the same datasets as in the previous lab:\n",
    "\n",
    "- **Boston Housing** dataset  \n",
    "- **Credit Card Default** dataset (subsampled to **n = 12,000** observations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eACWITJkLLfo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.4.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/nl/f_x36gk55bjgcqv4y5k__plw0000gq/T/ipykernel_81073/1094043221.py\", line 14, in <module>\n",
      "    from sklearn.model_selection import train_test_split\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/__init__.py\", line 70, in <module>\n",
      "    from sklearn.base import clone  # noqa: E402\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 19, in <module>\n",
      "    from sklearn.utils._metadata_requests import _MetadataRequester, _routing_enabled\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n",
      "    from sklearn.utils._chunking import gen_batches, gen_even_slices\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n",
      "    from sklearn.utils._param_validation import Interval, validate_params\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n",
      "    from sklearn.utils.validation import _is_arraylike_not_scalar\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 24, in <module>\n",
      "    from sklearn.utils._array_api import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n",
      "    from sklearn.utils.fixes import parse_version\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/fixes.py\", line 389, in <module>\n",
      "    import pyarrow\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.4.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_multiarray_umath.py:46\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     48\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.4.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBoostingRegressor\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/__init__.py:70\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build, _distributor_init  \u001b[38;5;66;03m# noqa: E402 F401\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     73\u001b[0m _submodules \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    112\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_missing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_pandas_na, is_scalar_nan\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/__init__.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_indexing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing, resample, shuffle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_chunking.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:24\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     DataConversionWarning,\n\u001b[1;32m     21\u001b[0m     NotFittedError,\n\u001b[1;32m     22\u001b[0m     PositiveSpectrumWarning,\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     _asarray_with_order,\n\u001b[1;32m     26\u001b[0m     _convert_to_numpy,\n\u001b[1;32m     27\u001b[0m     _is_numpy_namespace,\n\u001b[1;32m     28\u001b[0m     _max_precision_float_dtype,\n\u001b[1;32m     29\u001b[0m     get_namespace,\n\u001b[1;32m     30\u001b[0m     get_namespace_and_device,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_pandas_df, is_pandas_df_or_series\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isfinite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_array_api.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_api_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_df_or_series\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# TODO: complete __all__\u001b[39;00m\n\u001b[1;32m     23\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpx\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# we import xpx here just to re-export it, need this to appease ruff\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/fixes.py:389\u001b[0m\n\u001b[1;32m    387\u001b[0m PYARROW_VERSION_BELOW_17 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     pyarrow_version \u001b[38;5;241m=\u001b[39m parse_version(pyarrow\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pyarrow_version \u001b[38;5;241m<\u001b[39m parse_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m17.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyarrow/__init__.py:65\u001b[0m\n\u001b[1;32m     63\u001b[0m _gc_enabled \u001b[38;5;241m=\u001b[39m _gc\u001b[38;5;241m.\u001b[39misenabled()\n\u001b[1;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n\u001b[1;32m     67\u001b[0m     _gc\u001b[38;5;241m.\u001b[39menable()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyarrow/lib.pyx:36\u001b[0m, in \u001b[0;36minit pyarrow.lib\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Boosting Lab (Google Colab) — Boston Housing + Credit Default\n",
    "#   - Data loading and splits (Boston 90/10, Credit 60/40)\n",
    "#   - 1.1 Boosting for regression trees (Boston) using sklearn\n",
    "#   - Variable importance + partial dependence (lstat, rm)\n",
    "#   - Test MSE for n_estimators=10000\n",
    "#   - Test MSE curve vs number of trees (100..10000 by 100)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "RANDOM_STATE = 123\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JjbCajri357"
   },
   "source": [
    "### 1.1 Boosting for regression trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "e8xT7KL7LPGG",
    "outputId": "bf40e768-89d9-4cb5-d20c-b5443405719a"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0) Load Boston Housing data (CMU StatLib format) — same as your earlier method\n",
    "# ============================================================\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=r\"\\s+\", skiprows=22, header=None)\n",
    "\n",
    "data = np.hstack([\n",
    "    raw_df.values[::2, :],      # even rows: 13 columns\n",
    "    raw_df.values[1::2, :2]     # odd rows: first 2 columns\n",
    "])\n",
    "target = raw_df.values[1::2, 2] # odd rows: 3rd column is MEDV\n",
    "\n",
    "feature_names = [\n",
    "    \"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\", \"RM\", \"AGE\",\n",
    "    \"DIS\", \"RAD\", \"TAX\", \"PTRATIO\", \"B\", \"LSTAT\"\n",
    "]\n",
    "\n",
    "boston = pd.DataFrame(data, columns=feature_names)\n",
    "boston[\"MEDV\"] = target\n",
    "\n",
    "boston.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4mbOShcLRVg",
    "outputId": "40fc134b-cf7d-46b9-c218-a44765fcef15"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) Train/Test split (90/10) — Boston (matches your R split idea)\n",
    "# ============================================================\n",
    "X_boston = boston.drop(columns=[\"MEDV\"])\n",
    "y_boston = boston[\"MEDV\"]\n",
    "\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "    X_boston, y_boston, test_size=0.10, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Boston train:\", X_train_b.shape, \" Boston test:\", X_test_b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "id": "rRLmpYN-LW8x",
    "outputId": "298cdfee-86aa-447f-b255-4a8f77aa4e25"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1.1 Boosting for Regression Trees (Boston)\n",
    "# R(gbm) settings:\n",
    "#   n.trees = 10000\n",
    "#   shrinkage = 0.01\n",
    "#   interaction.depth = 8\n",
    "#\n",
    "# sklearn analogue:\n",
    "#   n_estimators = 10000\n",
    "#   learning_rate = 0.01\n",
    "#   max_depth = 8   (depth of individual regression trees)\n",
    "# ============================================================\n",
    "boston_boost = GradientBoostingRegressor(\n",
    "    n_estimators=10000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=8,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "boston_boost.fit(X_train_b, y_train_b)\n",
    "\n",
    "# Variable importance (gbm \"relative influence\" analogue)\n",
    "imp = pd.Series(boston_boost.feature_importances_, index=X_train_b.columns).sort_values(ascending=False)\n",
    "imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "OesKFm_zLZjD",
    "outputId": "a3e05dbb-6dba-4f16-d608-2dbcbcb4ef10"
   },
   "outputs": [],
   "source": [
    "# Plot variable importance\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(imp.index[::-1], imp.values[::-1])\n",
    "plt.xlabel(\"Relative Influence (Feature Importance)\")\n",
    "plt.ylabel(\"Predictor\")\n",
    "plt.title(\"Boosted Regression Trees: Variable Importance (Boston)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "a1WQ71_-LdFr",
    "outputId": "2f9e6c1f-ce44-422b-f349-1f536cae7d8e"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Partial dependence plots (analog to plot(gbm_model, i=\"lstat\") and i=\"rm\")\n",
    "# ============================================================\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "PartialDependenceDisplay.from_estimator(boston_boost, X_train_b, [\"LSTAT\"], ax=ax[0])\n",
    "PartialDependenceDisplay.from_estimator(boston_boost, X_train_b, [\"RM\"], ax=ax[1])\n",
    "ax[0].set_title(\"Partial Dependence: LSTAT\")\n",
    "ax[1].set_title(\"Partial Dependence: RM\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PV2X7ZdnLfO5",
    "outputId": "ff4cb6cf-6586-4d38-940c-60c5eda37871"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Prediction on testing sample + Test MSE (5 decimal places)\n",
    "# ============================================================\n",
    "boston_boost_pred_test = boston_boost.predict(X_test_b)\n",
    "test_mse_10000 = mean_squared_error(y_test_b, boston_boost_pred_test)\n",
    "\n",
    "print(f\"Boosting Test MSE (n_estimators=10000): {test_mse_10000:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "r7F5GNymLhAP",
    "outputId": "5d1050b9-d600-49d6-c8d7-04831a31c792"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Investigate how test error changes with different number of trees\n",
    "#\n",
    "# IMPORTANT FIXES vs earlier draft:\n",
    "# - No stray/unused 'test.err' variable.\n",
    "# - Robust check that we actually collected points.\n",
    "# - Correctly find and report the minimum MSE on the grid.\n",
    "# ============================================================\n",
    "ntree = list(range(100, 10001, 100))\n",
    "ntree_set = set(ntree)\n",
    "\n",
    "mse_curve = []\n",
    "trees_recorded = []\n",
    "\n",
    "ntree = list(range(100, 10001, 100))\n",
    "ntree_set = set(ntree)\n",
    "\n",
    "err = []             # Test MSE at each ntree value\n",
    "trees_recorded = []  # Corresponding number of trees\n",
    "\n",
    "for t, yhat in enumerate(boston_boost.staged_predict(X_test_b), start=1):\n",
    "    if t in ntree_set:\n",
    "        err.append(mean_squared_error(y_test_b, yhat))\n",
    "        trees_recorded.append(t)\n",
    "\n",
    "# Plot Test MSE vs number of trees\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(trees_recorded, err, linewidth=2)\n",
    "plt.xlabel(\"n.trees (n_estimators)\")\n",
    "plt.ylabel(\"Test MSE\")\n",
    "plt.title(\"Boosting (Boston): Test MSE vs Number of Trees\")\n",
    "\n",
    "# Horizontal dashed line at the minimum Test MSE on this grid\n",
    "plt.axhline(y=min(err), linestyle=\"--\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_idx = int(np.argmin(err))\n",
    "print(f\"Minimum Test MSE on this grid: {err[best_idx]:.5f} at n.trees = {trees_recorded[best_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cXifNgXiszx"
   },
   "source": [
    "### 1.2 Boosting for classification trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tb6kc34GkOB4"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AdaBoost (Classification) — Credit Card Default (Google Colab)\n",
    "# R(adabag::boosting) analogue in Python:\n",
    "#   - sklearn.ensemble.AdaBoostClassifier with decision tree stumps\n",
    "#   - Train/Test split: reuse your existing credit_train / credit_test if available\n",
    "#   - ROC curve + AUC on training and testing sets\n",
    "#   - Save the fitted model to disk (pickle), similar to save(.Rdata)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import pickle\n",
    "\n",
    "RANDOM_STATE = 123\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wo8ZSU7VkQJm",
    "outputId": "8044d40d-3958-4595-fd1f-72ef559041fc"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0) Load + split credit card data (ONLY run this cell if you do not already\n",
    "#    have credit_train and credit_test from earlier cells)\n",
    "# ============================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "credit_url = \"https://yanyudm.github.io/Data-Mining-R/lecture/data/credit_default.csv\"\n",
    "credit_data = pd.read_csv(credit_url)\n",
    "\n",
    "for col in [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]:\n",
    "    credit_data[col] = credit_data[col].astype(\"category\")\n",
    "\n",
    "credit_train, credit_test = train_test_split(\n",
    "    credit_data, test_size=0.40, random_state=RANDOM_STATE, stratify=credit_data[\"default.payment.next.month\"]\n",
    ")\n",
    "\n",
    "print(\"Credit train:\", credit_train.shape, \" Credit test:\", credit_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nliG0g8skSGE",
    "outputId": "87c421d1-2f31-43bd-997f-2b539031f94a"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) Prepare features and target (one-hot encode categorical variables)\n",
    "# ============================================================\n",
    "target_col = \"default.payment.next.month\"\n",
    "\n",
    "X_train = credit_train.drop(columns=[target_col])\n",
    "y_train = credit_train[target_col].astype(int)\n",
    "\n",
    "X_test = credit_test.drop(columns=[target_col])\n",
    "y_test = credit_test[target_col].astype(int)\n",
    "\n",
    "# One-hot encoding for categorical predictors (sklearn needs numeric input)\n",
    "X_train_enc = pd.get_dummies(X_train, drop_first=False)\n",
    "X_test_enc  = pd.get_dummies(X_test, drop_first=False)\n",
    "\n",
    "# Align columns so train/test have identical feature sets\n",
    "X_train_enc, X_test_enc = X_train_enc.align(X_test_enc, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "X_train_enc.shape, X_test_enc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfvZvmf7kUJl",
    "outputId": "2b9f68e0-856d-494f-db76-2e4de85240ae"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2) Fit AdaBoost classifier (analog to adabag::boosting)\n",
    "# IMPORTANT FIX:\n",
    "#   - Remove algorithm=\"SAMME.R\" (not supported in recent sklearn)\n",
    "# ============================================================\n",
    "base_tree = DecisionTreeClassifier(max_depth=1, random_state=RANDOM_STATE)\n",
    "\n",
    "credit_boost = AdaBoostClassifier(\n",
    "    estimator=base_tree,\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.5,\n",
    "    algorithm=\"SAMME\",          # <- this is the only supported option in recent sklearn\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "credit_boost.fit(X_train_enc, y_train)\n",
    "\n",
    "print(\"AdaBoost fitted.\")\n",
    "print(\"n_estimators:\", credit_boost.n_estimators)\n",
    "print(\"learning_rate:\", credit_boost.learning_rate)\n",
    "print(\"algorithm:\", credit_boost.algorithm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XCr2mFktkWhw",
    "outputId": "8d89b711-6271-4fd8-b1e1-6200aebde228"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3) Save the trained model (Python equivalent of save(..., .Rdata))\n",
    "# ============================================================\n",
    "with open(\"credit_boost.pkl\", \"wb\") as f:\n",
    "    pickle.dump(credit_boost, f)\n",
    "\n",
    "print(\"Saved model to: credit_boost.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "Wbh-HKxkkYH8",
    "outputId": "21967a49-2483-4b42-f417-7387a7a5f3f2"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4) Training ROC + AUC (R code uses training predictions)\n",
    "# ============================================================\n",
    "train_prob = credit_boost.predict_proba(X_train_enc)[:, 1]\n",
    "train_auc = roc_auc_score(y_train, train_prob)\n",
    "\n",
    "fpr_tr, tpr_tr, _ = roc_curve(y_train, train_prob)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr_tr, tpr_tr, label=f\"Training ROC (AUC = {train_auc:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"AdaBoost (Credit Default): Training ROC Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "train_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "oAN9CzhOkaYM",
    "outputId": "7326264a-c0e4-4b81-a177-82c298587699"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5) Testing ROC + AUC\n",
    "# ============================================================\n",
    "test_prob = credit_boost.predict_proba(X_test_enc)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, test_prob)\n",
    "\n",
    "fpr_te, tpr_te, _ = roc_curve(y_test, test_prob)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr_te, tpr_te, label=f\"Testing ROC (AUC = {test_auc:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"AdaBoost (Credit Default): Testing ROC Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "test_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-ZJg4ywMQW9",
    "outputId": "59f49375-ae97-46be-c137-5ba522a9eec8"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "jupyter nbconvert --to html ///content/7C_Advanced_Tree_Models_–_Boosting_Trees"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
